## Руководство для разработчиков

Короткие инструкции по встраиванию новых компонентов, запуску модулей и отладке.

### Структура репозитория (вкратце)

- `datagenerator2.0b.py` — генерация синтетических данных (nodes, edges, orders, weather, scenarios).
- `run_pipeline.py` — оркестратор исполнения всех этапов.
- `ml/` — набор модулей модели и вспомогательных утилит:
  - `embeddings.py`, `gnn_models.py`, `learn_to_route.py`, `demand_forecast.py`, `transport_classifier.py`, `rl_routing.py`, `route_optimizer.py`, `utils.py`, `evaluate.py`, `ts_transformer.py`.
- `models/` — конфиги и артефакты (файлы .json, .pt, .pkl).
- `dataset/` — CSV входных данных (есть примеры сгенерированных CSV).
- `tools/` — вспомогательные утилиты для отчетов и сборки метрик.

### Как добавить новый ML-модуль

1. Создайте `ml/my_module.py` с функциями `train()` и `predict()` или `main()` для запуска как скрипта.
2. Включите опцию вызова в `run_pipeline.py`, добавив шаг в последовательность.
3. Сохраняйте артефакты в `models/` с понятными именами и метаданных в JSON (`*_config.json`, `*_metrics.json`).

### Контракт модуля (рекомендуемый)

- Вход: пути к CSV-файлам в `dataset/`.
- Выход: артефакты в `models/` (модель + JSON с метриками) и опционально предсказания в `models/*.csv`.
- Ошибки: модуль должен вернуть ненулевой код выхода при критических ошибках, или аккуратно логировать и пропустить шаг при отсутствии необязательных зависимостей.

### Тесты

- В репозитории нет автоматических unit-тестов; рекомендуется добавить минимальные pytest-тесты для:
  - Валидации загрузки CSV (парсинг столбцов)
  - Проверки основных утилит (resolve_path, build_graph_from_csvs)
  - Smoke test для `run_pipeline.py` с опцией `--dry-run` (можно реализовать)

### Code Style

- Следуйте PEP8/flake8; форматирование black приветствуется.
